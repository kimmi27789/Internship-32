{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa634683",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebd3c560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3f4c3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f92b7cf",
   "metadata": {},
   "source": [
    "# Q-1) To scrape data for ‚ÄúData Analyst‚Äù Job position in ‚ÄúBangalore‚Äù location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data from naukri.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afbaf987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Req</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai</td>\n",
       "      <td>Latentview</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Mangaluru/Mangalore, Pune...</td>\n",
       "      <td>Coresight Research, Inc.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Varite</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - CRM Platform</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Jar</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For Data Analyst (DA)/ Team Lead (TL) -...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Call For Clinical Data Analyst - Hyd/Bangalore...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Payroll Transformation Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Payroll Transformation Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Master Data Management Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                                Senior Data Analyst   \n",
       "1                                       Data Analyst   \n",
       "2                                       Data Analyst   \n",
       "3                        Data Analyst - CRM Platform   \n",
       "4                                       Data Analyst   \n",
       "5  Hiring For Data Analyst (DA)/ Team Lead (TL) -...   \n",
       "6  Call For Clinical Data Analyst - Hyd/Bangalore...   \n",
       "7                Payroll Transformation Data Analyst   \n",
       "8                Payroll Transformation Data Analyst   \n",
       "9            Master Data Management Business Analyst   \n",
       "\n",
       "                                            Location  \\\n",
       "0                       Bangalore/Bengaluru, Chennai   \n",
       "1  Bangalore/Bengaluru, Mangaluru/Mangalore, Pune...   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "6  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "               Company Name Experience Req  \n",
       "0                Latentview        3-6 Yrs  \n",
       "1  Coresight Research, Inc.        4-8 Yrs  \n",
       "2                    Varite        2-5 Yrs  \n",
       "3         Artech infosystem        1-6 Yrs  \n",
       "4                       Jar        0-4 Yrs  \n",
       "5                 Cognizant        3-8 Yrs  \n",
       "6                 Cognizant        6-9 Yrs  \n",
       "7         Arrow Electronics       5-10 Yrs  \n",
       "8         Arrow Electronics        3-7 Yrs  \n",
       "9                 Accenture        6-8 Yrs  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connect to the driver\n",
    "driver = webdriver.Chrome(r'F:\\Project Data\\flip robo\\chromedriver.exe')\n",
    "\n",
    "#opening the page on automated chrome browser\n",
    "driver.get('https://www.naukri.com/')\n",
    "time.sleep(1)\n",
    "\n",
    "#entering designation and location as per the question\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "location = driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "location.send_keys('Bangalore')\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "#click the search button\n",
    "search = driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[6]')\n",
    "search.click()\n",
    "time.sleep(5)\n",
    "\n",
    "#initializing empty lists \n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "exp_required = []\n",
    "\n",
    "#scraping job_title from given page\n",
    "title = driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title[0:10]:\n",
    "    job_title.append(i.text.strip())\n",
    "    \n",
    "#scraping job location\n",
    "loc = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in loc[0:10]:\n",
    "    job_location.append(i.text.strip())\n",
    "    \n",
    "#scraping company name\n",
    "company = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company[0:10]:\n",
    "    company_name.append(i.text.strip())\n",
    "    \n",
    "#print(company_name)\n",
    "#scraping experience\n",
    "exp = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in exp[0:10]:\n",
    "    exp_required.append(i.text.strip())\n",
    "    \n",
    "#creating a data frame\n",
    "df = pd.DataFrame({\"Job Title\":job_title,\"Location\":job_location,\"Company Name\":company_name,\"Experience Req\":exp_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5a935f",
   "metadata": {},
   "source": [
    "# Q-2) To scrape data for ‚ÄúData Scientist‚Äù Job position in ‚ÄúBangalore‚Äù location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data from naukri.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8d5bde9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mongodb Database Administrator, Maria DB or Ca...</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Mphasis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...</td>\n",
       "      <td>ZS Associates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, New Delhi, Chennai</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Computer Vision</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                               Data Science Manager   \n",
       "2  Mongodb Database Administrator, Maria DB or Ca...   \n",
       "3                   Assistant Manager - Data Science   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                              Senior Data Scientist   \n",
       "7            Data Scientist: Artificial Intelligence   \n",
       "8                   Data Scientist - Computer Vision   \n",
       "9                              Senior Data Scientist   \n",
       "\n",
       "                                            Location             Company Name  \n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...                Accenture  \n",
       "1  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...                Accenture  \n",
       "2  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...                  Mphasis  \n",
       "3                  Bangalore/Bengaluru, Mumbai, Pune               CitiusTech  \n",
       "4  Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...            ZS Associates  \n",
       "5  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...            Tech Mahindra  \n",
       "6    Bangalore/Bengaluru, Mumbai, New Delhi, Chennai  Boston Consulting Group  \n",
       "7                                Bangalore/Bengaluru                      IBM  \n",
       "8                                Bangalore/Bengaluru                  Walmart  \n",
       "9                 Bangalore/Bengaluru, Pune, Chennai                    Wipro  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connect to the driver\n",
    "driver = webdriver.Chrome(r'F:\\Project Data\\flip robo\\chromedriver.exe')\n",
    "\n",
    "#opening the page on automated chrome browser\n",
    "driver.get('https://www.naukri.com/')\n",
    "time.sleep(1)\n",
    "\n",
    "#entering designation and location as per the question\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')\n",
    "time.sleep(1)\n",
    "\n",
    "location = driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "location.send_keys('Bangalore')\n",
    "time.sleep(1)\n",
    "\n",
    "#click the search button\n",
    "search = driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[6]')\n",
    "search.click()\n",
    "time.sleep(5)\n",
    "\n",
    "#initializing empty lists \n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "\n",
    "#scraping job_title from given page\n",
    "title = driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title[0:10]:\n",
    "    job_title.append(i.text.strip())\n",
    "    \n",
    "#scraping job location\n",
    "loc = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in loc[0:10]:\n",
    "    job_location.append(i.text.strip())\n",
    "    \n",
    "#scraping company name\n",
    "company = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company[0:10]:\n",
    "    company_name.append(i.text.strip())\n",
    "    \n",
    "#creating a data frame\n",
    "df = pd.DataFrame({\"Job Title\":job_title,\"Location\":job_location,\"Company Name\":company_name})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc3e7da",
   "metadata": {},
   "source": [
    "# Q-3) You have to use the location and salary filter.\n",
    "- You have to scrape data for ‚ÄúData Scientist‚Äù designation for first 10 job results.\n",
    "- You have to scrape the job-title, job-location, company name, experience required.\n",
    "- The location filter to be used is ‚ÄúDelhi/NCR‚Äù. The salary filter to be used is ‚Äú3-6‚Äù lakhs\n",
    "- webiste - naukri.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "574ff44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Req</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...</td>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lead ML Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Module Lead - BIDW</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Mphasis</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Uber</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist/AIML Engineer</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>upGrad</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Geospatial Data Engineer/Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Louis Dreyfus Commodities</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Python Programming Language Data Science Pract...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Senior Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Merck</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                               Data Science Manager   \n",
       "2                                     Data Scientist   \n",
       "3                                  Lead ML Scientist   \n",
       "4                                 Module Lead - BIDW   \n",
       "5                                   Data Scientist I   \n",
       "6                       Data Scientist/AIML Engineer   \n",
       "7                 Geospatial Data Engineer/Scientist   \n",
       "8  Python Programming Language Data Science Pract...   \n",
       "9                    Data Scientist - Senior Analyst   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "1  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "2  Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...   \n",
       "3                        Bangalore/Bengaluru, Mumbai   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                Company Name Experience Req  \n",
       "0                  Accenture        2-4 Yrs  \n",
       "1                  Accenture        4-7 Yrs  \n",
       "2              ZS Associates        5-8 Yrs  \n",
       "3          Fractal Analytics       6-10 Yrs  \n",
       "4                    Mphasis        5-8 Yrs  \n",
       "5                       Uber        5-7 Yrs  \n",
       "6                     upGrad        0-2 Yrs  \n",
       "7  Louis Dreyfus Commodities       5-10 Yrs  \n",
       "8                  Accenture        4-6 Yrs  \n",
       "9                      Merck        1-3 Yrs  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connect to the driver\n",
    "driver = webdriver.Chrome(r'F:\\Project Data\\flip robo\\chromedriver.exe')\n",
    "\n",
    "#opening the page on automated chrome browser\n",
    "driver.get('https://www.naukri.com/')\n",
    "time.sleep(1)\n",
    "\n",
    "#entering designation as per the question\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')\n",
    "time.sleep(1)\n",
    "\n",
    "#click the search button\n",
    "search = driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[6]')\n",
    "search.click()\n",
    "time.sleep(5)\n",
    "\n",
    "#apply location filter\n",
    "loc_filter = driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/section[1]/div[2]/div[6]/div[2]/div[3]/label/i')\n",
    "loc_filter.click()\n",
    "time.sleep(2)\n",
    "\n",
    "#apply salary filter\n",
    "salary_filter = driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/i')\n",
    "salary_filter.click()\n",
    "time.sleep(2)\n",
    "\n",
    "#initializing empty lists for job-title, job-location, company name, experience required. \n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "exp_required = []\n",
    "\n",
    "#scraping job_title from given page\n",
    "title = driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title[0:10]:\n",
    "    job_title.append(i.text.strip())\n",
    "    \n",
    "#scraping job location\n",
    "loc = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in loc[0:10]:\n",
    "    job_location.append(i.text.strip())\n",
    "    \n",
    "#scraping company name\n",
    "company = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company[0:10]:\n",
    "    company_name.append(i.text.strip())\n",
    "    \n",
    "#scraping experience\n",
    "exp = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in exp[0:10]:\n",
    "    exp_required.append(i.text.strip())\n",
    "    \n",
    "#creating a data frame\n",
    "df = pd.DataFrame({\"Job Title\":job_title,\"Location\":job_location,\"Company Name\":company_name,\"Experience Req\":exp_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e49c1da",
   "metadata": {},
   "source": [
    "# Q-4) Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:Brand, Product Description, Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "026143de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SKYZA INDIA</td>\n",
       "      <td>UV Protection, Mirrored Spectacle Sunglasses (...</td>\n",
       "      <td>‚Çπ399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>Gradient, UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>‚Çπ272</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>‚Çπ799</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>‚Çπ179</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>‚Çπ199</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Mirrored Aviator Sunglasses (55)</td>\n",
       "      <td>‚Çπ339</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Over-sized Sunglasses (65)</td>\n",
       "      <td>‚Çπ383</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Oval Sunglasses (Free Size)</td>\n",
       "      <td>‚Çπ1,699</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized Rectangular Sunglasses (60)</td>\n",
       "      <td>‚Çπ538</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>FOSSIL</td>\n",
       "      <td>Others Oval Sunglasses (56)</td>\n",
       "      <td>‚Çπ3,719</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand Name                                        Description  \\\n",
       "0         SKYZA INDIA  UV Protection, Mirrored Spectacle Sunglasses (...   \n",
       "1              GANSTA    Gradient, UV Protection Aviator Sunglasses (57)   \n",
       "2            Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "3   SHAAH COLLECTIONS                UV Protection Round Sunglasses (54)   \n",
       "4          LIZA ANGEL      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "..                ...                                                ...   \n",
       "95          ROYAL SON                   Mirrored Aviator Sunglasses (55)   \n",
       "96             PIRASO           UV Protection Over-sized Sunglasses (65)   \n",
       "97           Fastrack          UV Protection Oval Sunglasses (Free Size)   \n",
       "98          ROYAL SON              Polarized Rectangular Sunglasses (60)   \n",
       "99             FOSSIL                        Others Oval Sunglasses (56)   \n",
       "\n",
       "     Price Discount  \n",
       "0     ‚Çπ399  60% off  \n",
       "1     ‚Çπ272  86% off  \n",
       "2     ‚Çπ799  20% off  \n",
       "3     ‚Çπ179  86% off  \n",
       "4     ‚Çπ199  50% off  \n",
       "..     ...      ...  \n",
       "95    ‚Çπ339  85% off  \n",
       "96    ‚Çπ383  15% off  \n",
       "97  ‚Çπ1,699  73% off  \n",
       "98    ‚Çπ538  40% off  \n",
       "99  ‚Çπ3,719  82% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connect to the driver\n",
    "driver = webdriver.Chrome(r'F:\\Project Data\\flip robo\\chromedriver.exe')\n",
    "\n",
    "#opening the page on automated chrome browser\n",
    "driver.get('https://www.flipkart.com/')\n",
    "time.sleep(2)\n",
    "\n",
    "#close the login prompt\n",
    "login_dialog_box = driver.find_element(By.XPATH,'//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "login_dialog_box.click()\n",
    "time.sleep(2)\n",
    "\n",
    "#enter sunglasses in search field\n",
    "search = driver.find_element(By.XPATH,'//input[@class=\"_3704LK\"]')\n",
    "search.send_keys('sunglasses')\n",
    "time.sleep(2)\n",
    "\n",
    "#click search icon\n",
    "search_icon = driver.find_element(By.XPATH,'//button[@class=\"L0Z3Pu\"]')\n",
    "search_icon.click()\n",
    "time.sleep(5)\n",
    "\n",
    "#initializing attributed need to be scraped\n",
    "brand_name = []\n",
    "description = []\n",
    "price = []\n",
    "discount = []\n",
    "\n",
    "#page contains 40 items only\n",
    "page = 1\n",
    "\n",
    "count_name = 0\n",
    "count_des = 0\n",
    "count_price = 0\n",
    "count_dist = 0\n",
    "\n",
    "while (page <= 3):\n",
    "    #scraping name from given page\n",
    "    name = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in name:\n",
    "        if(count_name<100):\n",
    "            brand_name.append(i.text.strip())\n",
    "            count_name = count_name + 1\n",
    "    #print(brand_name)\n",
    "            \n",
    "    #scraping description\n",
    "    des = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in des:\n",
    "        if(count_des<100):\n",
    "            description.append(i.text.strip())\n",
    "            count_des = count_des + 1\n",
    "    #print(description)\n",
    "    \n",
    "    #scraping price\n",
    "    pr = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in pr:\n",
    "        if(count_price<100):\n",
    "            price.append(i.text.strip())\n",
    "            count_price = count_price + 1\n",
    "    #print(price)\n",
    "\n",
    "    #scraping discount\n",
    "    disc = driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]//span')\n",
    "    for i in disc:\n",
    "        if(count_dist<100):\n",
    "            discount.append(i.text.strip())\n",
    "            count_dist = count_dist + 1\n",
    "    #print(discount)\n",
    "\n",
    "    #click next button\n",
    "    next_button = driver.find_elements(By.XPATH,'//a[@class=\"_1LKTO3\"]//span')\n",
    "    for i in next_button:\n",
    "        #print(\"i=\",i.text)\n",
    "        if (i.text == 'NEXT'):\n",
    "            page = page + 1\n",
    "            i.click()\n",
    "            time.sleep(1)\n",
    "\n",
    "    #print (\"Length name:\",{len(brand_name)})   \n",
    "#creating a data frame\n",
    "df = pd.DataFrame({\"Brand Name\":brand_name,\"Description\":description,\"Price\":price,\"Discount\":discount})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bb67f2",
   "metadata": {},
   "source": [
    "# Q-5) Scrape 100 reviews data from flipkart.com for iphone11 phone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "993a34e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>I'm Really happy with the product\\nDelivery wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Gift this to your loved ones fabulous product ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Awesome purchase. Amazing phone with good batt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Gifted my man on his 30th birthday üéÇ He loves ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Always love the apple products, upgraded from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Does the job</td>\n",
       "      <td>phone is good but in display is 720p lcd in th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review Summary  \\\n",
       "0       5       Simply awesome   \n",
       "1       4      Value-for-money   \n",
       "2       5     Perfect product!   \n",
       "3       5  Best in the market!   \n",
       "4       5    Worth every penny   \n",
       "..    ...                  ...   \n",
       "95      5            Fabulous!   \n",
       "96      5     Perfect product!   \n",
       "97      3       Classy product   \n",
       "98      5              Awesome   \n",
       "99      5         Does the job   \n",
       "\n",
       "                                          Full Review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   I'm Really happy with the product\\nDelivery wa...  \n",
       "2   Amazing phone with great cameras and better ba...  \n",
       "3   Great iPhone very snappy experience as apple k...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  Gift this to your loved ones fabulous product ...  \n",
       "96  Awesome purchase. Amazing phone with good batt...  \n",
       "97  Gifted my man on his 30th birthday üéÇ He loves ...  \n",
       "98  Always love the apple products, upgraded from ...  \n",
       "99  phone is good but in display is 720p lcd in th...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connect to the driver\n",
    "driver = webdriver.Chrome(r'F:\\Project Data\\flip robo\\chromedriver.exe')\n",
    "\n",
    "#opening the page on automated chrome browser\n",
    "driver.get('https://www.flipkart.com/')\n",
    "time.sleep(5)\n",
    "\n",
    "#close the login prompt\n",
    "login_dialog_box = driver.find_element(By.XPATH,'//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "login_dialog_box.click()\n",
    "time.sleep(2)\n",
    "\n",
    "#enter iphone 11 in search field\n",
    "search = driver.find_element(By.XPATH,'//input[@class=\"_3704LK\"]')\n",
    "search.send_keys('iphone 11')\n",
    "time.sleep(2)\n",
    "\n",
    "#click search icon\n",
    "search_icon = driver.find_element(By.XPATH,'//button[@class=\"L0Z3Pu\"]')\n",
    "search_icon.click()\n",
    "time.sleep(2)\n",
    "\n",
    "#open tke link of first product on screen\n",
    "driver.find_element(By.XPATH,'//a[@class=\"_1fQZEK\"]').click()\n",
    "time.sleep(2)\n",
    "\n",
    "#switch to the active window\n",
    "driver.switch_to.window(driver.window_handles[1])\n",
    "time.sleep(2)\n",
    "\n",
    "#check reviews\n",
    "temp = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[7]/div/a').click()\n",
    "time.sleep(2)\n",
    "\n",
    "#initializing attributed need to be scraped\n",
    "rating = []\n",
    "review_summary = []\n",
    "full_review = []\n",
    "\n",
    "# each page contains 10 reviews only\n",
    "page = 1\n",
    "\n",
    "count_rating = 0\n",
    "count_review_summary = 0\n",
    "count_full_review = 0\n",
    "\n",
    "while (page <= 11):\n",
    "    #scraping rating from given page\n",
    "    rating_x = driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_x:\n",
    "        if(count_rating<100):\n",
    "            rating.append(i.text.strip())\n",
    "            count_rating = count_rating + 1\n",
    "    #print(rating)\n",
    "            \n",
    "    #scraping review summary\n",
    "    summary = driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in summary:\n",
    "        if(count_review_summary<100):\n",
    "            review_summary.append(i.text.strip())\n",
    "            count_review_summary = count_review_summary + 1\n",
    "    #print(review_summary)\n",
    "\n",
    "    #scraping full review\n",
    "    ful_rev = driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]//div//div')\n",
    "    for i in ful_rev:\n",
    "        if(count_full_review<100):\n",
    "            full_review.append(i.text.strip())\n",
    "            count_full_review = count_full_review + 1\n",
    "    #print(full_review)\n",
    "\n",
    "    #click next button\n",
    "    next_button = driver.find_elements(By.XPATH,'//a[@class=\"_1LKTO3\"]//span')\n",
    "    for i in next_button:\n",
    "        #print(\"i=\",i.text)\n",
    "        if (i.text == 'NEXT'):\n",
    "            page = page + 1\n",
    "            i.click()\n",
    "            time.sleep(1)\n",
    "#print(\"len of full_review\",len(full_review))\n",
    "#creating a data frame\n",
    "df = pd.DataFrame({\"Rating\":rating,\"Review Summary\":review_summary,\"Full Review\":full_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c87e070",
   "metadata": {},
   "source": [
    "# Q-6) Scrape data for first 100 sneakers you find when you visit flipkart.com and search for ‚Äúsneakers‚Äù in the search field. You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2f0902b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ580</td>\n",
       "      <td>41% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Shoes Sneakers For Men</td>\n",
       "      <td>‚Çπ470</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ1,499</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Lightweight Pack Of 1 Trendy Sneakers Sneakers...</td>\n",
       "      <td>‚Çπ259</td>\n",
       "      <td>56% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>UME INTERNATIONAL</td>\n",
       "      <td>Men's White Faux Leather Sneakers For Men</td>\n",
       "      <td>‚Çπ590</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>RS-FAST GO FOR Sneakers For Men</td>\n",
       "      <td>‚Çπ636</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>x 1DER Jack V2 Sneakers For Men</td>\n",
       "      <td>‚Çπ849</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>HIGHLANDER</td>\n",
       "      <td>Casual Sneakers White Shoes For Girls And Snea...</td>\n",
       "      <td>‚Çπ599</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>UME INTERNATIONAL</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ590</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand Name                                        Description  \\\n",
       "0              Labbin                                   Sneakers For Men   \n",
       "1            RapidBox                                   Sneakers For Men   \n",
       "2              BRUTON               Modern Trendy Shoes Sneakers For Men   \n",
       "3            RED TAPE                                   Sneakers For Men   \n",
       "4              BRUTON  Lightweight Pack Of 1 Trendy Sneakers Sneakers...   \n",
       "..                ...                                                ...   \n",
       "95  UME INTERNATIONAL          Men's White Faux Leather Sneakers For Men   \n",
       "96             BRUTON                    RS-FAST GO FOR Sneakers For Men   \n",
       "97           Roadster                    x 1DER Jack V2 Sneakers For Men   \n",
       "98         HIGHLANDER  Casual Sneakers White Shoes For Girls And Snea...   \n",
       "99  UME INTERNATIONAL                                   Sneakers For Men   \n",
       "\n",
       "     Price Discount  \n",
       "0     ‚Çπ499  50% off  \n",
       "1     ‚Çπ580  41% off  \n",
       "2     ‚Çπ470  63% off  \n",
       "3   ‚Çπ1,499  70% off  \n",
       "4     ‚Çπ259  56% off  \n",
       "..     ...      ...  \n",
       "95    ‚Çπ590  74% off  \n",
       "96    ‚Çπ636  71% off  \n",
       "97    ‚Çπ849  50% off  \n",
       "98    ‚Çπ599  50% off  \n",
       "99    ‚Çπ590  77% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connect to the driver\n",
    "driver = webdriver.Chrome(r'F:\\Project Data\\flip robo\\chromedriver.exe')\n",
    "\n",
    "#opening the page on automated chrome browser\n",
    "driver.get('https://www.flipkart.com/')\n",
    "time.sleep(2)\n",
    "\n",
    "#close the login prompt\n",
    "login_dialog_box = driver.find_element(By.XPATH,'//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "login_dialog_box.click()\n",
    "time.sleep(2)\n",
    "\n",
    "#enter sneakers in search field\n",
    "search = driver.find_element(By.XPATH,'//input[@class=\"_3704LK\"]')\n",
    "search.send_keys('sneakers')\n",
    "time.sleep(2)\n",
    "\n",
    "#click search icon\n",
    "search_icon = driver.find_element(By.XPATH,'//button[@class=\"L0Z3Pu\"]')\n",
    "search_icon.click()\n",
    "time.sleep(1)\n",
    "\n",
    "#initializing attributed need to be scraped\n",
    "brand_name = []\n",
    "description = []\n",
    "price = []\n",
    "discount = []\n",
    "\n",
    "#page contains 40 items only\n",
    "page = 1\n",
    "\n",
    "count_name = 0\n",
    "count_des = 0\n",
    "count_price = 0\n",
    "count_dist = 0\n",
    "\n",
    "while (page <= 3):\n",
    "    #scraping name from given page\n",
    "    name = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in name:\n",
    "        if(count_name<100):\n",
    "            brand_name.append(i.text.strip())\n",
    "            count_name = count_name + 1\n",
    "    #print(brand_name)\n",
    "            \n",
    "    #scraping description\n",
    "    des = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in des:\n",
    "        if(count_des<100):\n",
    "            description.append(i.text.strip())\n",
    "            count_des = count_des + 1\n",
    "    #print(description)\n",
    "    \n",
    "    #scraping price\n",
    "    pr = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in pr:\n",
    "        if(count_price<100):\n",
    "            price.append(i.text.strip())\n",
    "            count_price = count_price + 1\n",
    "    #print(price)\n",
    "\n",
    "    #scraping discount\n",
    "    disc = driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]//span')\n",
    "    for i in disc:\n",
    "        if(count_dist<100):\n",
    "            discount.append(i.text.strip())\n",
    "            count_dist = count_dist + 1\n",
    "    #print(discount)\n",
    "\n",
    "    #click next button\n",
    "    next_button = driver.find_elements(By.XPATH,'//a[@class=\"_1LKTO3\"]//span')\n",
    "    for i in next_button:\n",
    "        #print(\"i=\",i.text)\n",
    "        if (i.text == 'NEXT'):\n",
    "            page = page + 1\n",
    "            i.click()\n",
    "            time.sleep(1)\n",
    "\n",
    "    #print (\"Length name:\",{len(brand_name)})   \n",
    "#creating a data frame\n",
    "df = pd.DataFrame({\"Brand Name\":brand_name,\"Description\":description,\"Price\":price,\"Discount\":discount})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b9260d",
   "metadata": {},
   "source": [
    "# Q-7)Go to the link - https://www.myntra.com/shoes Set second Price filter and Color filter to ‚ÄúBlack‚Äù. and scrape forst 100 shoe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c6fdef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Go Walk Walking Shoes</td>\n",
       "      <td>6374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men GO WALK - TERRA Shoes</td>\n",
       "      <td>8499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Fuse 2.0 Training Shoes</td>\n",
       "      <td>6399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men 4DFWD_Pulse Running Shoes</td>\n",
       "      <td>11199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Go Run Hyper Burst Running</td>\n",
       "      <td>7224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Women Enlighten Shoes</td>\n",
       "      <td>5949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Women EQ21 Running Shoes</td>\n",
       "      <td>6019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Men Leather Sneakers</td>\n",
       "      <td>6509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Louis Philippe</td>\n",
       "      <td>Men Solid Formal Derbys</td>\n",
       "      <td>5949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand Name                        Description  Price\n",
       "0         Skechers          Men Go Walk Walking Shoes   6374\n",
       "1         Skechers          Men GO WALK - TERRA Shoes   8499\n",
       "2             Puma        Men Fuse 2.0 Training Shoes   6399\n",
       "3           ADIDAS      Men 4DFWD_Pulse Running Shoes  11199\n",
       "4         Skechers     Men Go Run Hyper Burst Running   7224\n",
       "..             ...                                ...    ...\n",
       "95            Puma              Women Enlighten Shoes   5949\n",
       "96          ADIDAS           Women EQ21 Running Shoes   6019\n",
       "97    Hush Puppies  Men Solid Leather Formal Slip-Ons   9999\n",
       "98  Tommy Hilfiger               Men Leather Sneakers   6509\n",
       "99  Louis Philippe            Men Solid Formal Derbys   5949\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connect to the driver\n",
    "driver = webdriver.Chrome(r'F:\\Project Data\\flip robo\\chromedriver.exe')\n",
    "\n",
    "#opening the page on automated chrome browser\n",
    "driver.get('https://www.myntra.com/shoes')\n",
    "time.sleep(2)\n",
    "\n",
    "#set color filter to black\n",
    "driver.find_elements(By.XPATH,'//li[@class=\"colour-listItem\"]')[0].click()\n",
    "time.sleep(2)\n",
    "\n",
    "#set second price filter\n",
    "driver.find_elements(By.XPATH,'//ul[@class=\"price-list\"]//li')[1].click()\n",
    "time.sleep(2)\n",
    "\n",
    "#initializing attributed need to be scraped\n",
    "brand_name = []\n",
    "description = []\n",
    "price = []\n",
    "\n",
    "#page contains 40 items only\n",
    "page = 1\n",
    "\n",
    "count_name = 0\n",
    "count_des = 0\n",
    "count_price = 0\n",
    "\n",
    "while (page <= 2):\n",
    "    #scraping name from given page\n",
    "    name = driver.find_elements(By.XPATH,'//div[@class=\"product-productMetaInfo\"]//h3[@class=\"product-brand\"]')\n",
    "    for i in name:\n",
    "        if(count_name<100):\n",
    "            brand_name.append(i.text.strip())\n",
    "            count_name = count_name + 1\n",
    "    #print(brand_name)\n",
    "            \n",
    "    #scraping description\n",
    "    des = driver.find_elements(By.XPATH,'//div[@class=\"product-productMetaInfo\"]//h4[@class=\"product-product\"]')\n",
    "    for i in des:\n",
    "        if(count_des<100):\n",
    "            description.append(i.text.strip())\n",
    "            count_des = count_des + 1\n",
    "    #print(description)\n",
    "    \n",
    "    #scraping price\n",
    "    pr = driver.find_elements(By.XPATH,'//div[@class=\"product-price\"]')\n",
    "    for i in pr:\n",
    "        if(count_price<100):\n",
    "            price.append(i.text.strip().split('Rs. ')[1])\n",
    "            count_price = count_price + 1\n",
    "    #print(price)\n",
    "\n",
    "    #click next button\n",
    "    driver.find_element(By.XPATH,'//li[@class=\"pagination-next\"]//a').click()\n",
    "    page = page + 1\n",
    "    time.sleep(1)\n",
    "\n",
    "#creating a data frame\n",
    "df = pd.DataFrame({\"Brand Name\":brand_name,\"Description\":description,\"Price\":price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157edd72",
   "metadata": {},
   "source": [
    "# Q-8) Go to webpage https://www.amazon.in/ Enter ‚ÄúLaptop‚Äù in the search field and then click the search icon. Then set CPU Type filter to ‚ÄúIntel Core i7‚Äù. After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fd58034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>64,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3\" FHD ...</td>\n",
       "      <td>1,00,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FH...</td>\n",
       "      <td>93,290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>64,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td>80,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo Yoga 7i 11th Gen Intel Core i7-1165G7 1...</td>\n",
       "      <td>1,11,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 Intel Core i7-12700H 1...</td>\n",
       "      <td>1,09,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Price\n",
       "0  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...    64,990\n",
       "1  Fujitsu UH-X 11th Gen Intel Core i7 13.3\" FHD ...  1,00,000\n",
       "2  ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FH...    93,290\n",
       "3  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...    79,990\n",
       "4  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...    64,990\n",
       "5  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....    77,990\n",
       "6  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...    86,990\n",
       "7  HP Pavilion x360 11th Gen Intel Core i7 14 inc...    80,990\n",
       "8  Lenovo Yoga 7i 11th Gen Intel Core i7-1165G7 1...  1,11,000\n",
       "9  Lenovo IdeaPad Gaming 3 Intel Core i7-12700H 1...  1,09,990"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connect to the driver\n",
    "driver = webdriver.Chrome(r'F:\\Project Data\\flip robo\\chromedriver.exe')\n",
    "\n",
    "#opening the page on automated chrome browser\n",
    "driver.get('https://www.amazon.in/')\n",
    "time.sleep(2)\n",
    "\n",
    "#enter Laptop in the search field\n",
    "driver.find_element(By.XPATH,'//input[@class=\"nav-input nav-progressive-attribute\"]').send_keys('Laptop')\n",
    "time.sleep(2)\n",
    "\n",
    "#click the search button\n",
    "driver.find_element(By.XPATH,'//span[@class=\"nav-search-submit-text nav-sprite nav-progressive-attribute\"]').click()\n",
    "time.sleep(2)\n",
    "\n",
    "#select CPU type filter as \"Intel Core i7\"\n",
    "driver.find_element(By.XPATH,'//li[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]//i').click()\n",
    "time.sleep(2)\n",
    "\n",
    "#initializing attributed need to be scraped\n",
    "title = []\n",
    "rating = []\n",
    "price = []\n",
    "\n",
    "#scraping first 10 titles\n",
    "temp = driver.find_elements(By.XPATH,'//div[@class=\"a-section a-spacing-small a-spacing-top-small\"]//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in temp[0:10]:\n",
    "    title.append(i.text.strip())\n",
    "\n",
    "#print(title)\n",
    "\n",
    "#scraping price\n",
    "temp = driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in temp[0:10]:\n",
    "    price.append(i.text.strip())\n",
    "#print(price)\n",
    "\n",
    "#rating not able to scrape\n",
    "\n",
    "#creating a data frame\n",
    "df = pd.DataFrame({\"Title\":title,\"Price\":price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1227e8",
   "metadata": {},
   "source": [
    "# Q-9) scrape data for first 10 job results for Data Scientist Designation in Noida location. https://www.ambitionbox.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593e2edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the driver\n",
    "driver = webdriver.Chrome(r'F:\\Project Data\\flip robo\\chromedriver.exe')\n",
    "\n",
    "#opening the page on automated chrome browser\n",
    "driver.get('https://www.ambitionbox.com/')\n",
    "\n",
    "#click job option\n",
    "driver.find_element(By.XPATH,'/html/body/div/div/div/div[1]/header/nav/ul/li[5]').click()\n",
    "time.sleep(2)\n",
    "\n",
    "#enter data scientist in search option\n",
    "driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input').send_keys('Data Scientist')\n",
    "\n",
    "#click search button\n",
    "driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button').click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c00ea0a",
   "metadata": {},
   "source": [
    "Not able to do Q-9 and Q-10 because website has changed and steps guided through the assignment sheet are not matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3597952f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
